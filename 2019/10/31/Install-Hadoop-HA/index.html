
<!DOCTYPE html>
<html lang="en" class="loading">
<head><meta name="generator" content="Hexo 3.9.0">
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    <meta name="viewport" content="width=device-width, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>Install Hadoop HA&lt;br&gt;（安装Hadoop的HA） - JacksonYuu - Personal Blog</title>
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="google" content="notranslate">
    <meta name="keywords" content="Fechin,"> 
    <meta name="description" content="I will use Hadoop 2.7.3 for Hadoop cluster and ha configuration. Here I use seven virtual machines,,"> 
    <meta name="author" content="JacksonYuu"> 
    <link rel="alternative" href="atom.xml" title="JacksonYuu - Personal Blog" type="application/atom+xml"> 
    <link rel="icon" href="/img/favicon.png"> 
    <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css">
    <link rel="stylesheet" href="/css/diaspora.css">
    <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
    <script>
         (adsbygoogle = window.adsbygoogle || []).push({
              google_ad_client: "ca-pub-8691406134231910",
              enable_page_level_ads: true
         });
    </script>
    <script async custom-element="amp-auto-ads" src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js">
    </script>
</head>
</html>
<body class="loading">
    <span id="config-title" style="display:none">JacksonYuu - Personal Blog</span>
    <div id="loader"></div>
    <div id="single">
    <div id="top" style="display: block;">
    <div class="bar" style="width: 0;"></div>
    <a class="icon-home image-icon" href="javascript:;" data-url="https://JacksonYuu.github.io"></a>
    <div title="播放/暂停" class="icon-play"></div>
    <h3 class="subtitle">Install Hadoop HA<br>（安装Hadoop的HA）</h3>
    <div class="social">
        <!--<div class="like-icon">-->
            <!--<a href="javascript:;" class="likeThis active"><span class="icon-like"></span><span class="count">76</span></a>-->
        <!--</div>-->
        <div>
            <div class="share">
                <a title="获取二维码" class="icon-scan" href="javascript:;"></a>
            </div>
            <div id="qr"></div>
        </div>
    </div>
    <div class="scrollbar"></div>
</div>

    <div class="section">
        <div class="article">
    <div class='main'>
        <h1 class="title">Install Hadoop HA<br>（安装Hadoop的HA）</h1>
        <div class="stuff">
            <span>十月 31, 2019</span>
            
  <ul class="post-tags-list"><li class="post-tags-list-item"><a class="post-tags-list-link" href="/tags/HA/">HA</a></li><li class="post-tags-list-item"><a class="post-tags-list-link" href="/tags/Hadoop/">Hadoop</a></li><li class="post-tags-list-item"><a class="post-tags-list-link" href="/tags/Install/">Install</a></li></ul>


        </div>
        <div class="content markdown">
            <p>I will use Hadoop 2.7.3 for Hadoop cluster and ha configuration. Here I use seven virtual machines, two with a namenode（nn1，nn2）, two with a resource manager（rm1，rm2）, and three hosts for the storage and zookeeper cluster of edits，And the storage of datanode（zk1，zk2，zk3）.</p>
<p>（我将会使用hadoop2.7.3进行Hadoop集群以及HA的配置，在这里我使用了7台虚拟机，两台各有一个NameNode（nn1，nn2），两台各有一个ResourceManager（rm1，rm2），三台主机成为Edits的存放和zookeeper集群，以及datanode的存放（zk1，zk2，zk3））</p>
<p>Before that, we need to build the Java environment (JDK1.8). Here is the installation package:</p>
<p>（在此之前需要首先搭建好Java环境（jdk1.8），以下是此次搭建的安装包：）</p>
<p>Download all files（所有文件下载）：<a href="https://pan.baidu.com/s/1FJjHd_9l5ZYCOHZnoyUsPg" target="_blank" rel="noopener">https://pan.baidu.com/s/1FJjHd_9l5ZYCOHZnoyUsPg</a> </p>
<p>Extraction Code（提取码）：7cor</p>
<h3 id="1、First-step（第一步）"><a href="#1、First-step（第一步）" class="headerlink" title="1、First step（第一步）"></a>1、First step（第一步）</h3><p>Create a virtual machine first, and then the rest can be created by cloning. After creation, upload the Hadoop installation package on windows to the virtual machine, and then decompress it with the command:</p>
<p>（首先创建一台虚拟机，然后其余虚拟机可以通过克隆进行创建。创建完成之后将windows上面的Hadoop安装包上传至虚拟机当中，然后通过命令进行解压：）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf hadoop-2.7.3.tar -C /usr/local/hadoop</span><br></pre></td></tr></table></figure>

<h3 id="2、second-step（第二步）"><a href="#2、second-step（第二步）" class="headerlink" title="2、second step（第二步）"></a>2、second step（第二步）</h3><p>Enter the etc/hadoop directory of the newly decompressed file and add to hadoop-env.sh:</p>
<p>（进入刚刚解压后文件的etc/hadoop目录下，向hadoop-env.sh中添加：）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">export JAVA_HOME=/usr/lib/jvm/java-8-oracle（jdk的路径）</span><br></pre></td></tr></table></figure>

<p>Modify core-site.xml to:（修改core-site.xml为：）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line"></span><br><span class="line">	   &lt;!-- 指定hdfs的nameservice为ns1(相当于Federation的名称) --&gt;</span><br><span class="line">	   &lt;!-- Federation可以有多个，以逗号隔开 --&gt;</span><br><span class="line">       &lt;property&gt;</span><br><span class="line">                &lt;name&gt;fs.defaultFS&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;hdfs://ns1&lt;/value&gt;</span><br><span class="line">       &lt;/property&gt;</span><br><span class="line">       </span><br><span class="line">       &lt;!-- 指定hadoop的临时目录 --&gt;</span><br><span class="line">       &lt;property&gt;</span><br><span class="line">               &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;</span><br><span class="line">               &lt;value&gt;file:/home/hadoop/tmp&lt;/value&gt;</span><br><span class="line">       &lt;/property&gt;</span><br><span class="line">       </span><br><span class="line">       &lt;!-- 指定zookeeper地址 --&gt;</span><br><span class="line">       &lt;property&gt;</span><br><span class="line">               &lt;name&gt;ha.zookeeper.quorum&lt;/name&gt;</span><br><span class="line">               &lt;value&gt;zk1:2181,zk2:2181,zk3:2181&lt;/value&gt;</span><br><span class="line">       &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>

<p>Modify hdfs-site.xml to:（修改hdfs-site.xml为：）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line"></span><br><span class="line">	   &lt;!-- 指定hdfs的nameservice为ns1，要和core-site.xml中的名称一致 --&gt;</span><br><span class="line">       &lt;property&gt;</span><br><span class="line">                &lt;name&gt;dfs.nameservices&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;ns1&lt;/value&gt;</span><br><span class="line">       &lt;/property&gt;</span><br><span class="line">       </span><br><span class="line">       &lt;!-- ns1下面有两个NameNode，分别是nn1，nn2 --&gt;</span><br><span class="line">       &lt;property&gt;</span><br><span class="line">                &lt;name&gt;dfs.ha.namenodes.ns1&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;nn1,nn2&lt;/value&gt;</span><br><span class="line">       &lt;/property&gt;</span><br><span class="line">       </span><br><span class="line">       &lt;!-- nn1的RPC通信地址 --&gt;</span><br><span class="line">       &lt;property&gt;</span><br><span class="line">                &lt;name&gt;dfs.namenode.rpc-address.ns1.nn1&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;nn1:9000&lt;/value&gt;</span><br><span class="line">       &lt;/property&gt;</span><br><span class="line">       </span><br><span class="line">       &lt;!-- nn1的http通信地址 --&gt;</span><br><span class="line">       &lt;property&gt;</span><br><span class="line">                &lt;name&gt;dfs.namenode.http-address.ns1.nn1&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;nn1:50070&lt;/value&gt;</span><br><span class="line">       &lt;/property&gt;</span><br><span class="line">       </span><br><span class="line">       &lt;!-- nn2的RPC通信地址 --&gt;</span><br><span class="line">       &lt;property&gt;</span><br><span class="line">                &lt;name&gt;dfs.namenode.rpc-address.ns1.nn2&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;nn2:9000&lt;/value&gt;</span><br><span class="line">       &lt;/property&gt;</span><br><span class="line">       </span><br><span class="line">       &lt;!-- nn1的http通信地址 --&gt;</span><br><span class="line">       &lt;property&gt;</span><br><span class="line">                &lt;name&gt;dfs.namenode.http-address.ns1.nn2&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;nn2:50070&lt;/value&gt;</span><br><span class="line">       &lt;/property&gt;</span><br><span class="line">       </span><br><span class="line">       &lt;!-- 指定NameNode的元数据在JournalNode上的存放位置 --&gt;</span><br><span class="line">       &lt;property&gt;</span><br><span class="line">                &lt;name&gt;dfs.namenode.shared.edits.dir&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;qjournal://zk1:8485;zk2:8485;zk3:8485/ns1&lt;/value&gt;</span><br><span class="line">       &lt;/property&gt;</span><br><span class="line">       </span><br><span class="line">       &lt;!-- 指定JournalNode在本地磁盘存放数据的位置 --&gt;</span><br><span class="line">       &lt;property&gt;</span><br><span class="line">                &lt;name&gt;dfs.journalnode.edits.dir&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;/usr/local/hadoop/hadoop-2.7.3/journaldata&lt;/value&gt;</span><br><span class="line">       &lt;/property&gt;</span><br><span class="line">       </span><br><span class="line">       &lt;!-- 开启NameNode失败时自动切换 --&gt;</span><br><span class="line">       &lt;property&gt;</span><br><span class="line">                &lt;name&gt;dfs.ha.automatic-failover.enabled&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;true&lt;/value&gt;</span><br><span class="line">       &lt;/property&gt;</span><br><span class="line">       </span><br><span class="line">       &lt;!-- 配置失败自动切换实现方式 --&gt;</span><br><span class="line">       &lt;!-- 使用的是Apache自带的实现方式，也可用户自定义 --&gt;</span><br><span class="line">       &lt;property&gt;</span><br><span class="line">                &lt;name&gt;dfs.client.failover.proxy.provider.ns1&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;org.apache.hadoop.hdfs.server.namenode.</span><br><span class="line">                ha.ConfiguredFailoverProxyProvidervalue&gt;</span><br><span class="line">       &lt;/property&gt;</span><br><span class="line">       </span><br><span class="line">       &lt;!-- 配置隔离机制方法，多个机制用换行分割 --&gt;</span><br><span class="line">       &lt;!-- 这里使用的是ssh kill -9 namenode以及用户自定义脚本 --&gt;</span><br><span class="line">       &lt;property&gt;</span><br><span class="line">                &lt;name&gt;dfs.ha.fencing.methods&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;</span><br><span class="line">                	sshfence</span><br><span class="line">                	shell(/bin/true)</span><br><span class="line">                &lt;/value&gt;</span><br><span class="line">       &lt;/property&gt;</span><br><span class="line">       </span><br><span class="line">       &lt;!-- 使用sshfence隔离机制的配置 --&gt;</span><br><span class="line">       &lt;!-- 配置ssh免密登录的私有密钥的位置 --&gt;</span><br><span class="line">       &lt;property&gt;</span><br><span class="line">                &lt;name&gt;dfs.ha.fencing.ssh.private-key-files&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;/home/hadoop/.ssh/id_rsa&lt;/value&gt;</span><br><span class="line">       &lt;/property&gt;</span><br><span class="line">       </span><br><span class="line">       &lt;!-- 隔离机制的超时时间(单位毫秒) --&gt;</span><br><span class="line">       &lt;property&gt;</span><br><span class="line">                &lt;name&gt;dfs.ha.fencing.ssh.connect-timeout&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;30000&lt;/value&gt;</span><br><span class="line">       &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>

<p>Modify mapred-site.xml to:（修改mapred-site.xml为：）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line"></span><br><span class="line">	   &lt;!-- 指定MR框架使用yarn方式 --&gt;</span><br><span class="line">       &lt;property&gt;</span><br><span class="line">                &lt;name&gt;mapreduce.framework.name&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;yarn&lt;/value&gt;</span><br><span class="line">       &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>

<p>Modify yarn-site.xml to:（修改yarn-site.xml为：）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">&lt;configuration&gt;</span><br><span class="line"></span><br><span class="line">	   &lt;!-- 开启RM的高可用 --&gt;</span><br><span class="line">       &lt;property&gt;</span><br><span class="line">                &lt;name&gt;yarn.resourcemanager.ha.enabled&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;true&lt;/value&gt;</span><br><span class="line">       &lt;/property&gt;</span><br><span class="line">       </span><br><span class="line">       &lt;!-- 指定RM的cluster名称 --&gt;</span><br><span class="line">       &lt;property&gt;</span><br><span class="line">                &lt;name&gt;yarn.resourcemanager.cluster-id&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;yrc&lt;/value&gt;</span><br><span class="line">       &lt;/property&gt;</span><br><span class="line">       </span><br><span class="line">       &lt;!-- 指定RM的名称 --&gt;</span><br><span class="line">       &lt;property&gt;</span><br><span class="line">                &lt;name&gt;yarn.resourcemanager.ha.rm-ids&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;rm1,rm2&lt;/value&gt;</span><br><span class="line">       &lt;/property&gt;</span><br><span class="line">       </span><br><span class="line">       &lt;!-- 指定rm1的地址 --&gt;</span><br><span class="line">       &lt;property&gt;</span><br><span class="line">                &lt;name&gt;yarn.resourcemanager.hostname.rm1&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;rm1&lt;/value&gt;</span><br><span class="line">       &lt;/property&gt;</span><br><span class="line">       </span><br><span class="line">       &lt;!-- 指定rm2的地址 --&gt;</span><br><span class="line">       &lt;property&gt;</span><br><span class="line">                &lt;name&gt;yarn.resourcemanager.hostname.rm2&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;rm2&lt;/value&gt;</span><br><span class="line">       &lt;/property&gt;</span><br><span class="line">       </span><br><span class="line">       &lt;!-- 指定zk集群地址 --&gt;</span><br><span class="line">       &lt;property&gt;</span><br><span class="line">                &lt;name&gt;yarn.resourcemanager.zk-address&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;zk1:2181,zk2:2181,zk3:2181&lt;/value&gt;</span><br><span class="line">       &lt;/property&gt;</span><br><span class="line">       </span><br><span class="line">       &lt;!-- 在执行MR任务时使用shuffle机制 --&gt;</span><br><span class="line">       &lt;property&gt;</span><br><span class="line">                &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</span><br><span class="line">                &lt;value&gt;mapreduce_shuffle&lt;/value&gt;</span><br><span class="line">       &lt;/property&gt;</span><br><span class="line">&lt;/configuration&gt;</span><br></pre></td></tr></table></figure>

<h3 id="3、Third-step（第三步）"><a href="#3、Third-step（第三步）" class="headerlink" title="3、Third step（第三步）"></a>3、Third step（第三步）</h3><p>Since the start-dfs.sh file uses SSH to start the process, you need to configure the unclassified login of namenode and datanode.</p>
<p>（由于start-dfs.sh文件启动时使用的是ssh进行启动进程，所以需要配置NameNode和DataNode的无密登录）</p>
<p>In the NN1 node, you need to configure the unclassified login of nn2, ZK1, ZK2, ZK3:</p>
<p>（在nn1节点需要配置nn2，zk1，zk2，zk3的无密登录：）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen（生成密钥）</span><br><span class="line"></span><br><span class="line">ssh-copy-id nn2（将生成的密钥拷贝到其他节点当中）</span><br></pre></td></tr></table></figure>

<p>Because the start-yarn.sh file starts rm with a local start, RM2 is not started. SSH is used to start the process when nm is started, so it is necessary to configure the unclassified login between RM1 and nm node.</p>
<p>（由于start-yarn.sh文件启动rm时使用的是本地启动，所以并不会启动rm2。启动nm时使用的ssh进行进程启动，所以需要配置rm1与nm节点的无密登录）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ssh-keygen（生成密钥）</span><br><span class="line"></span><br><span class="line">ssh-copy-id zk1（将生成的密钥拷贝到nm节点当中）</span><br></pre></td></tr></table></figure>

<h3 id="4、Fourth-step（第四步）"><a href="#4、Fourth-step（第四步）" class="headerlink" title="4、Fourth step（第四步）"></a>4、Fourth step（第四步）</h3><p>Since the start-dfs.sh and start-yarn.sh files will be used to read the NN and nm nodes, configure the slaves (since NN and nm are on the same node here, you don’t need to change):</p>
<p>（由于启动start-dfs.sh和start-yarn.sh文件会使用到slaves文件来读取nn和nm节点，所以配置slaves（由于在这里nn和nm在同一节点上，所以可不必更改）：）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">vi slaves</span><br><span class="line"></span><br><span class="line">zk1</span><br><span class="line">zk2</span><br><span class="line">zk3</span><br></pre></td></tr></table></figure>

<p>Distribute the configured files to other nodes.（将配置好的文件分发给其他节点）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">scp -r /usr/local/hadoop/hadoop-2.7.3 nn2:/usr/local/hadoop/hadoop-2.7.3</span><br><span class="line"></span><br><span class="line">scp -r /usr/local/hadoop/hadoop-2.7.3 rm1:/usr/local/hadoop/hadoop-2.7.3</span><br><span class="line"></span><br><span class="line">scp -r /usr/local/hadoop/hadoop-2.7.3 rm2:/usr/local/hadoop/hadoop-2.7.3</span><br><span class="line"></span><br><span class="line">scp -r /usr/local/hadoop/hadoop-2.7.3 zk1:/usr/local/hadoop/hadoop-2.7.3</span><br><span class="line"></span><br><span class="line">scp -r /usr/local/hadoop/hadoop-2.7.3 zk2:/usr/local/hadoop/hadoop-2.7.3</span><br><span class="line"></span><br><span class="line">scp -r /usr/local/hadoop/hadoop-2.7.3 zk3:/usr/local/hadoop/hadoop-2.7.3</span><br></pre></td></tr></table></figure>

<h3 id="5、Fifth-step（第五步）"><a href="#5、Fifth-step（第五步）" class="headerlink" title="5、Fifth step（第五步）"></a>5、Fifth step（第五步）</h3><p>Set up the zookeeper cluster in ZK1, ZK2 and ZK3. I won’t explain it in detail here. You can see my zookeeper cluster.</p>
<p>（在zk1，zk2，zk3中搭建好zookeeper集群，这里就不详细解说了，可以看我的zookeeper集群搭建。）</p>
<h3 id="6、Sixth-step（第六步）"><a href="#6、Sixth-step（第六步）" class="headerlink" title="6、Sixth step（第六步）"></a>6、Sixth step（第六步）</h3><p>Configuration of environmental variables（配置好环境变量）</p>
<p>Add to / etc / profile:（向/etc/profile中添加：）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">export HADOOP_HOME=/usr/local/hadoop/hadoop-2.7.3</span><br><span class="line"></span><br><span class="line">export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin</span><br></pre></td></tr></table></figure>

<p>Use after adding:（添加完成之后使用：）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scp -r /etc/profile nn2:/etc/profile（将环境信息发送给个个节点）</span><br><span class="line"></span><br><span class="line">source /etc/profile（在各个节点使用将环境变量生效）</span><br></pre></td></tr></table></figure>

<p>To start, follow the steps below:（在启动时要按照一下步骤启动：）</p>
<ol>
<li><p>First, start the zookeeper cluster on ZK1.（首先在zk1上面启动zookeeper集群。）</p>
</li>
<li><p>Then start the journal node on ZK1, ZK2 and ZK3. After that, you can start all processes directly using start-dfs.sh.</p>
<p>（然后在zk1，zk2，zk3上面启动journalnode。（只需在第一次启动的时候），之后可以直接使用start-dfs.sh启动所有进程）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">hadoop-daemon.sh start journalnode</span><br><span class="line"></span><br><span class="line">jps（使用jps命令查看进程，如果有JournalNode则成功）</span><br></pre></td></tr></table></figure>
</li>
<li><p>Format namenode in NN1 node.（在nn1节点格式化namenode）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hadoop namenode -format（在tmp目录生成文件，core-site.xml中所设置的路径）</span><br><span class="line"></span><br><span class="line">scp -r /home/hadoop/tmp nn2:/home/hadoop/tmp</span><br><span class="line">（也可使用hdfs namenode -bootstrapStandby）</span><br></pre></td></tr></table></figure>
</li>
<li><p>Format zkfc on NN1 node.（在nn1节点上格式化ZKFC）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">hdfs zkfc -formatzk</span><br></pre></td></tr></table></figure>
</li>
<li><p>Start HDFS on NN1 node.（在nn1节点上启动hdfs）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">start-dfs.sh</span><br></pre></td></tr></table></figure>
</li>
<li><p>Start YARN on rm1 node.（在rm1节点上启动yarn）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">start0-yarn.sh</span><br></pre></td></tr></table></figure>

</li>
</ol>

            <!--[if lt IE 9]><script>document.createElement('audio');</script><![endif]-->
            <audio id="audio" loop="1" preload="auto" controls="controls" data-autoplay="false">
                <source type="audio/mpeg" src="">
            </audio>
            
                <ul id="audio-list" style="display:none">
                    
                        
                            <li title='0' data-url='http://link.hhtjim.com/163/5146554.mp3'></li>
                        
                    
                        
                            <li title='1' data-url='http://link.hhtjim.com/qq/001faIUs4M2zna.mp3'></li>
                        
                    
                </ul>
            
        </div>
        
    <div id='gitalk-container' class="comment link"
        data-ae='false'
        data-ci=''
        data-cs=''
        data-r='JacksonYuu.github.io'
        data-o='JacksonYuu'
        data-a='JacksonYuu'
        data-d='true'
    >查看评论</div>


    </div>
    
</div>


    </div>
</div>
</body>
<script src="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script>
<script src="//lib.baomitu.com/jquery/1.8.3/jquery.min.js"></script>
<script src="/js/plugin.js"></script>
<script src="/js/diaspora.js"></script>
<link rel="stylesheet" href="/photoswipe/photoswipe.css">
<link rel="stylesheet" href="/photoswipe/default-skin/default-skin.css">
<script src="/photoswipe/photoswipe.min.js"></script>
<script src="/photoswipe/photoswipe-ui-default.min.js"></script>

<!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">
    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>
    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">
        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>
        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">
            <div class="pswp__top-bar">
                <!--  Controls are self-explanatory. Order can be changed. -->
                <div class="pswp__counter"></div>
                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
                <button class="pswp__button pswp__button--share" title="Share"></button>
                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>
                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                      <div class="pswp__preloader__cut">
                        <div class="pswp__preloader__donut"></div>
                      </div>
                    </div>
                </div>
            </div>
            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div> 
            </div>
            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>
            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>
            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>
        </div>
    </div>
</div>




</html>
